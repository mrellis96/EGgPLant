#!/bin/bash
# EGgPLant
echo "EGgPLant V1.0 by Morgan Ellis and Owen Holland"

usage()
{
echo
echo "EcoGenetics Lab Pipeline for Demupltiplexing Sequences"
echo 
echo "Usage: eggplant -d [-f] [-r] [-l] [-p] [-t] [-y] [-n] [-m] [-o] [-b] [-v] [-c] [-h]"
echo "Example: eggplant -d RawFastq -f ATCG -r CTAG -p G -t 280 -y 250 -l 10 -m 10 -o 0.99"
echo "Options:"
echo "d     Directory - The directory where the raw reads are stored"
echo "f     Forward primer - The sequence of the forward primer for cutadapt to remove"
echo "r     Reverse primer - The sequence of the reverse primer for cutadapt to remove"
echo "l     Minimum overlap - The minimum number of base pair overlap between the primer and the returned sequence before cutadapt will recognise the primer"
echo "p     Poly tails - Tells cutadapt to remove ploy tails. Add letter for base pair to remove"
echo "t     Truncate forward reads - Where you would like filterAndTrim to truncate the sequences (default = no truncation). Must be positive integer (see eggqual)"
echo "y     Truncate reverse reads - IF PAIRED END, where you would like filterAndTrim to truncate the reverse reads (default = no truncation). Must be positive integer"
echo "n     Minimum read length - Remove reads with length less than [n] (default = 20)"
echo "m     Minimum number of reads - Minimum number of reads per sequences allowed after chimera removal (default = 10). Must be positive integer"
echo "o     Cluster ASVs to OTUs based on similarity (0-1) (default = no clustering)"
echo "b		BLAST database - Database to BLAST output sequences against. Must be BLASTn formatted database (see eggdb)"
echo "v		Taxonomic map - Path to taxonomic mapping file for Blast Database to pass to LCA script"
echo "c     Citations - Citations from the various programs/packages used"
echo "h     Help - Displays help readout"
}

citation()
{ 
echo
echo "Citations"
echo
echo "Cutadapt"
echo "Martin M (2011) Cutadapt removes adapter sequences from high-throughput sequencing reads. EMBnet journal 17:10-12"
echo
echo "R base"
echo "R Core Team (2021). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/."
echo
echo "dada2"
echo "Callahan BJ, McMurdie PJ, Rosen MJ, Han AW, Johnson AJA, Holmes SP (2016). “DADA2: High-resolution sample inference from Illumina amplicon data.” Nature Methods, 13, 581-583. doi: 10.1038/nmeth.3869 (URL: https://doi.org/10.1038/nmeth.3869)."
echo
echo "vSearch"
echo "Rognes, T., Flouri, T., Nichols, B., Quince, C. and Mahé, F., 2016. VSEARCH: a versatile open source tool for metagenomics. PeerJ, 4, p.e2584."
} 

while getopts ":d:f:r:p:t:y:l:n:m:b:v:o:c h s" opt; do
        case $opt in
        d) raw="${OPTARG}"
        ;;
        f) fwdp="${OPTARG}"
        ;;
        r) revp="${OPTARG}"
        ;;
        p) poly="${OPTARG}"
        ;;
        t) fwdT="${OPTARG}"
        ;;
        y) revT="${OPTARG}"
        ;;
        l) minO="${OPTARG}"
        ;;
        n) minS="${OPTARG}"
        ;;
        m) minR="${OPTARG}"
        ;;
		b) bla="${OPTARG}"
		;;
		v) tmap="${OPTARG}"
		;;
        o) otu="${OPTARG}"
        ;;
        c) citation
        exit
        ;;
        h) usage
        exit
        ;;
		s) .EGS
		exit
		;;
        \?) echo 
        echo "Invalid Option"
        usage
        exit
        ;;
        esac
done

which R &> /dev/null
     	
if [ $? -ne 0 ]
	then
	echo "R not found. Please install R or run EGPL install script (install.eggplant.sh) before continuing"
	exit
fi
	
#Check if raw Dir exists
if [ ! -d "$raw" ]
	then
	echo "ERROR: Directory '$raw' Does Not Exist"
	exit
fi

if [ ! -d "outputs/" ]
	then
	mkdir outputs/
fi
#poly tails
if  [ ! $poly == "" ]
	then
	mkdir "$raw"_Poly/
	cd $raw
	for i in *.fastq.gz; 
	do SAMPLE=$(echo ${i} | sed "s/.fastq\.gz//") ; 
	cutadapt -j 8 -O 6 -a "$poly""$poly""$poly""$poly""$poly""$poly" -o ../"$raw"_Poly/${SAMPLE}.fastq.gz ${SAMPLE}.fastq.gz;
	done
	cd ../
	raw=""$raw"_Poly"	
fi


# Remove Primers

if [ ! $fwdp == "" ]
	then
	if  [ ! $revp == "" ]
		then #Paired
		mkdir "$raw"_Trimmed/
		cd $raw
		for i in *_R1_001.fastq.gz; 
		do SAMPLE=$(echo ${i} | sed "s/_R1_\001\.fastq\.gz//") ; 
		cutadapt -j 8 -m 90 -O 10 -g "$fwdp" -G "$revp" --trimmed-only -o ../"$raw"_Trimmed/${SAMPLE}_R1_001.fastq.gz -p ../"$raw"_Trimmed/${SAMPLE}_R2_001.fastq.gz ${SAMPLE}_R1_001.fastq.gz ${SAMPLE}_R2_001.fastq.gz;
		done 
		cd ../
		raw=""$raw"_Trimmed"
	else #Single
	mkdir "$raw"_Trimmed/
	cd $raw
	for i in *_R1_001.fastq.gz; 
	do SAMPLE=$(echo ${i} | sed "s/_R1_\001\.fastq\.gz//") ; 
	cutadapt -j 8 -m 90 -O 10 -g "$fwdp" --trimmed-only -o ../"$raw"_Trimmed/${SAMPLE}_R1_001.fastq.gz ${SAMPLE}_R1_001.fastq.gz;
	done 
	cd ../
	raw=""$raw"_Trimmed"	
	fi	
fi

#Check if "forward" directory exists, if present skip sorting step
if [ ! -d "forward/" ]
	then #sorting step
	mkdir forward
	cp "$raw"/*R1_001.fastq.gz forward/
		count=`ls  -1 "$raw"/*R2_001.fastq.gz 2>/dev/null | wc -l` ; 
		if [ $count != 0 ] #checks if Rawfastq has reverse reads
			then
			mkdir reverse
			cp "$raw"/*R2_001.fastq.gz reverse/
		fi
fi


#Checks if seqs are paired ends and run relevant script
if [[ "$(uname)" == "Linux" ]];
	then
	read -p "Are the sequences PAIRED END READS (Y/N/C)?"
	echo    # (optional) move to a new line
	if [[ $REPLY =~ ^[Yy]$ ]]; then
		EGPEP --fwdT $fwdT --revT $revT --minR $minR
	elif [[ $REPLY =~ ^[Nn]$ ]]; then
		EGSEP --fwdT $fwdT --minR $minR
	elif [[ $REPLY =~ ^[Cc]$ ]]; then
		exit
	fi
elif [[ "$(uname)" == "Darwin" ]];
	then
	read -p "Are the sequences PAIRED END READS (Y/N/C)?"
	echo    # (optional) move to a new line
	if [[ $REPLY =~ ^[Yy]$ ]]; then
		EGPEPM --fwdT $fwdT --revT $revT --minR $minR
	elif [[ $REPLY =~ ^[Nn]$ ]]; then
		EGSEPM --fwdT $fwdT --minR $minR
	elif [[ $REPLY =~ ^[Cc]$ ]]; then
		exit
	fi
fi

if [[ ! -f "outputs/Pipeline_Results.csv" ]];
	then
	echo 
	echo "ERROR"
	echo "Check R output above and try again"
	exit
fi
#copy and remove site names
#cp outputs/Pipeline_Results.csv outputs/Pipeline_Results.csv.bak
awk -F"," 'FNR == 1 { print }' outputs/Pipeline_Results.csv >outputs/site.tmp
tail -n +2 outputs/Pipeline_Results.csv > outputs/pipe.tmp
#relabel as ASV1-ASVN
awk -F"," '{ print "ASV"NR",", $0}' outputs/pipe.tmp >outputs/pipe.tmp2
#remove Sequence
if [[ "$(uname)" == "Linux" ]];
	then
	cut --complement -d',' -f2 outputs/pipe.tmp2 >outputs/pipe.tmp3
elif [[ "$(uname)" == "Darwin" ]];
	then 
	gcut --complement -d',' -f2 outputs/pipe.tmp2 >outputs/pipe.tmp3
fi
#add empty row
awk 'BEGIN{ print""}1' outputs/pipe.tmp3 >outputs/pipe.tmp4
#Paste all files together
paste outputs/site.tmp outputs/pipe.tmp4 >outputs/Pipeline_Results.csv
rm outputs/site.tmp outputs/pipe.tmp outputs/pipe.tmp2 outputs/pipe.tmp3 outputs/pipe.tmp4


if [ $otu > 0 ]
	then
	vsearch --cluster_size outputs/*.fa \
	--id "$otu" \
	--strand plus \
	--sizein \
	--sizeout \
	--fasta_width 0 \
	--relabel OTU_ \
	--centroids outputs/OTU.fasta \
	--otutabout outputs/OTU.txt \
	
	#Relabel OTU and ASV
	echo "Formating OTU TABLE - Please Wait"
	totcol=`head -1 outputs/OTU.txt | awk -F"\t" '{print NF}'`
	awk -F"\t" '{print $1}' outputs/OTU.txt > outputs/OTU.tmp

	for ((i=2;i<=$totcol;i++))
	do
	ID=`awk -F"\t" -v var="$i" '{print $(var)}' outputs/OTU.txt | head -1`
	OTU=`awk -F"\t" -v var="$i" '{if ($(var) == "1") print $1}' outputs/OTU.txt | perl -pe 's/\n/_/g' | perl -pe 's/_$//g'`
	awk -F"\t" -v var="$i" '{print $(var)}' outputs/OTU.txt | perl -pe "s/$ID/$ID\n$OTU/g" > outputs/OTU.tmp2
	paste outputs/OTU.tmp outputs/OTU.tmp2 > outputs/OTU.tmp3
	mv outputs/OTU.tmp3 outputs/OTU.tmp
	rm outputs/OTU.tmp2
	done
	cut -f2- outputs/OTU.tmp > outputs/OTU.tmp2
	head -2 outputs/OTU.tmp2 > outputs/OTU.tmp3
	mv outputs/OTU.tmp3 outputs/OTU.tmp
	rm outputs/OTU.tmp2
	#Transpose
	awk '
	{
	    for (i=1; i<=NF; i++)  {
	        a[NR,i] = $i
	    }
	}
	NF>p { p = NF }
	END {
	    for(j=1; j<=p; j++) {
	        str=a[1,j]
	        for(i=2; i<=NR; i++){
	            str=str" "a[i,j];
 	       }
        print str
	    }
	}' outputs/OTU.tmp > outputs/OTU.ASV.txt
	rm outputs/OTU.tmp
	#Copy and remove site names
	awk -F"," 'FNR == 1 { print }' outputs/Pipeline_Results.csv >outputs/site.tmp
	awk -F"," '{ print "," $0}' outputs/site.tmp >outputs/site.tmp2
	tail -n +2 outputs/Pipeline_Results.csv > outputs/pipe.tmp
	#sort asvoutput (other file) by ASV (ASV1,ASV2...ASV10)
	sort -V outputs/OTU.ASV.txt >outputs/otu.tmp
	#Remove ASV
	awk '{print $2}' outputs/otu.tmp >outputs/otu.tmp2
	#Add empty row and column
	awk -F"," '{ print "," $0}' outputs/pipe.tmp >outputs/pipe.tmp2
	#Paste all files together
	paste outputs/otu.tmp2 outputs/pipe.tmp2 >outputs/otu.tmp3
	awk 'BEGIN{print""}1' outputs/otu.tmp3 >outputs/otu.tmp4
	paste outputs/site.tmp2 outputs/otu.tmp4 >outputs/otu-asv.csv
	rm outputs/*tmp*
	
	echo "OTU-ASV found in outputs/OTU-ASV.txt, OTU's added to Pipeline_Results in out-asv.csv"

	if [[ "$(uname)" == "Linux" ]];
		then
		cut --complement -d',' -f2 outputs/otu-asv.csv >outputs/OTU.tmp
	elif [[ "$(uname)" == "Darwin" ]];
		then 
		gcut --complement -d',' -f2 outputs/otu-asv.csv >outputs/OTU.tmp
	fi
	
	declare -A sample_data#

	while IFS=',' read -r line; do
    	IFS=',' read -a values <<< "$line"
   	 	otu="${values[0]}"
    	for ((i = 1; i < ${#values[@]}; i++)); do
        	sample="${values[i]}"
        	sample_data["$otu,$i"]=$((sample_data["$otu,$i"] + sample))
    	done
	done < outputs/OTU.tmp
 Write the condensed data to the output file
	echo -n "otu" > OTU.csv
	for ((i = 1; i < ${#values[@]}; i++)); do
    	echo -n ", sample$i Total" >> OTU.csv
	done
	echo "" >> OTU.csv

	for otu in "${!sample_data[@]}"; do
    	echo "$otu, ${sample_data[$sample]}" >> OTU.csv
	done
	echo "OTU readcount in OTU.csv"
fi

if  [ ! $bla == "" ]
	then
	echo "Blasting sequences"
	blastn -query outputs/Results.fa -db $bla -outfmt 6 -out outputs/blast.out -perc_identity 90 -qcov_hsp_perc 80
	lcapath=which eggplant | sed 's!/[^/]*$!/!'
	python3 $lcapath outputs/blast.out $tmap
fi